{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Mixed Content Errors Fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "This first cell is the the only cell you should need to make changes to.\n",
    "Be sure the read all commented notes in this first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As a fail safe, the script saves 10 rows of urls at a time to the output file, designate the amount of rows here. \n",
    "## You can make this slightly higher for CSVs over 10k URLs, but this script is untested above that many URLs.\n",
    "rows_per_run = 10\n",
    "\n",
    "## If you'd like to loop through a CSV of URLs with URL in the 'url' column, paste that path here.\n",
    "## !IMPORTANT! As part of the fail safe described above, the script removes 10 rows of urls at a time from this source file, so be sure to have a backup of this file before you run this script on it. \n",
    "url_source = '/Users/you/Documents/url_list.csv'\n",
    "\n",
    "## Designate the path where you'd like the output of results. It will have 3 columns, URL, severe_count, warning_count\n",
    "url_output = '/Users/you/Documents/my_urls_mixed_content_errors.csv'\n",
    "\n",
    "## Designate the local path of your Chromedriver. If you need to install: https://chromedriver.chromium.org/downloads\n",
    "## On Mac, the Chromedriver path may not have a file extension. On Windows it will likely have an .exe file extension.\n",
    "chrome_path = '/Users/path/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports the necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This creates the blank output file as the url_output path designated above. No changes needed.\n",
    "df_output = pd.DataFrame(columns = ['url', 'severe_count', 'warning_count'])\n",
    "df_output.to_csv(url_output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program\n",
    "The program will loop through each URL, extracting Mixed Content errors from the Chrome Console Log (webdriver.Chrome.get_log).<br>\n",
    "It renders in full Chrome, including JavaScript, a rate of about 1-5 seconds per URL depending on host server speed and your internet connection.<br>\n",
    "It has not been tested on a list larger than 10k URLs.\n",
    "##### No changes are needed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enables browser logging & sets options\n",
    "## No further changes are required\n",
    "\n",
    "d = DesiredCapabilities.CHROME\n",
    "d['loggingPrefs'] = { 'browser':'ALL' }\n",
    "\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_experimental_option('w3c', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows to process...\n",
      "Skipping 1 URL that failed to render.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "df_source = pd.read_csv(url_source)\n",
    "\n",
    "while len(df_source) > 0:\n",
    "    new_rows = df_source.iloc[ 0: rows_per_run, : ]\n",
    "    print(str(len(new_rows)) + ' rows to process...')\n",
    "    url_list = new_rows['url'].tolist()\n",
    "    \n",
    "    console_output_df = pd.DataFrame()\n",
    "    \n",
    "    d = DesiredCapabilities.CHROME\n",
    "    d['loggingPrefs'] = { 'browser':'ALL' }\n",
    "    opt = webdriver.ChromeOptions()\n",
    "    opt.add_experimental_option('w3c', False)\n",
    "\n",
    "    for url in url_list:\n",
    "        driver = webdriver.Chrome(chrome_path, options=opt,desired_capabilities=d)\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "            console = driver.get_log('browser')\n",
    "\n",
    "            severe_count = 0\n",
    "            warning_count = 0\n",
    "\n",
    "            for log in console:\n",
    "                if \"Mixed Content\" in log['message'] and \"SEVERE\" in log['level']:\n",
    "                    severe_count += 1\n",
    "                if \"Mixed Content\" in log['message'] and \"WARNING\" in log['level']:\n",
    "                    warning_count += 1\n",
    "\n",
    "            console_results = {'severe_count':severe_count, 'warning_count':warning_count, 'loaded':True}\n",
    "            console_row_df = pd.DataFrame(data=console_results, index=[0])\n",
    "            console_row_df['url'] = url\n",
    "            console_output_df = console_output_df.append(console_row_df, ignore_index=True, sort=False)\n",
    "\n",
    "            # Quit browser each time to avoid zombies\n",
    "            driver.quit()\n",
    "    \n",
    "        ## A failsafe to prevent URLs that won't load from blocking script from continuing\n",
    "        ## There may be a more elegant solution for this\n",
    "        except:\n",
    "            console_results = {'severe_count':'', 'warning_count':'', 'loaded':False}\n",
    "            console_row_df = pd.DataFrame(data=console_results, index=[0])\n",
    "            console_row_df['url'] = url\n",
    "            console_output_df = console_output_df.append(console_row_df, ignore_index=True, sort=False)\n",
    "            driver.quit()\n",
    "            print(\"Skipping 1 URL that failed to render.\")\n",
    "\n",
    "        \n",
    "    # Read the output CSV, write the new rows, then write the output back again\n",
    "    df_output = pd.read_csv(url_output)\n",
    "    df_output = df_output.append(console_output_df, ignore_index=True, sort=False)\n",
    "    df_output.to_csv(url_output, index=False)\n",
    "    \n",
    "    # If all the URLs were processed, write the source list back without the processed URLs\n",
    "    updated_df = df_source.iloc[ rows_per_run+1: , : ]\n",
    "    updated_df.to_csv(url_source, index=False)\n",
    "    df_source = pd.read_csv(url_source)\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
